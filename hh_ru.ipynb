{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем профессии, которые будем добавлять в датафрейм\n",
    "jobs = ['Data Scientist', 'Data Analyst']\n",
    "vacancies = pd.DataFrame(columns=['employment', 'description', 'salary'])\n",
    "ids = []\n",
    "\n",
    "# Для каждой профессии отбираем только те, где указана зарплата: 'only_with_salary' : True\n",
    "for job in jobs:\n",
    "    url = 'https://api.hh.ru/vacancies'\n",
    "    params = {'text' : job,\n",
    "              'only_with_salary' : True,\n",
    "              'page' : 0,\n",
    "              'per_page' : 100}\n",
    "\n",
    "    st = requests.get(url, params).json()\n",
    "    # И по каждому id добавляем в датафрейм тип занятости, описание и зарплату\n",
    "    for i in range(len(st['items'])):\n",
    "        id = st['items'][i]['id']\n",
    "        if id in ids:\n",
    "            continue\n",
    "        ids.append(id)\n",
    "        vacancy = requests.get(\"https://api.hh.ru/vacancies/\" + id + \"?host=hh.ru\").json()\n",
    "        # Нас интересуют только те, где зарплата указана в рублях. Остальные пропускаем.\n",
    "        # Иначе цены будут в разных измерениях.\n",
    "        # При желании, можно приделать конвертацию по текущему курсу, но сейчас и так сойдёт)\n",
    "        if vacancy['salary']['currency'] != 'RUR':\n",
    "            continue\n",
    "        # Цены объявлены либо в конкретном диапазоне, либо \"от\", либо \"до\"\n",
    "        # Если диапазон не указан, то запишем крайнее значение\n",
    "        # Иначе, просто подсчитаем среднюю\n",
    "        if vacancy['salary']['from'] is None:\n",
    "            salary = int(vacancy['salary']['to'])\n",
    "        elif vacancy['salary']['to'] is None:\n",
    "            salary = int(vacancy['salary']['from'])\n",
    "        else:\n",
    "            salary = (int(vacancy['salary']['from']) + int(vacancy['salary']['to'])) // 2\n",
    "        vac_data = pd.DataFrame([[vacancy['employment']['id'],\n",
    "                                  vacancy['description'],\n",
    "                                  salary]],\n",
    "                                columns=['employment', 'description', 'salary'])\n",
    "        vacancies = vacancies.append(vac_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь создаём датафрейм для интересующих нс вакансий без указания зарплаты\n",
    "# Я взял с указанной для того, чтобы можно было проверить точность предскзаний\n",
    "# Просто не буду эту ЗП записывать\n",
    "target_vacancies = pd.DataFrame(columns=['employment', 'description', 'salary'])\n",
    "target_ids = ['38696758', '37080920']\n",
    "\n",
    "for target_id in target_ids:\n",
    "    vacancy = requests.get(\"https://api.hh.ru/vacancies/\" + target_id + \"?host=hh.ru\").json()\n",
    "    vac_data = pd.DataFrame([[vacancy['employment']['id'],\n",
    "                              vacancy['description'],\n",
    "                              'NaN']],\n",
    "                            columns=['employment', 'description', 'salary'])\n",
    "    target_vacancies = target_vacancies.append(vac_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нас интересуют только слова, поэтому убираем все лишние символы при помощи регулярных выражений,\n",
    "# а так же приводим все описания к нижнему регистру\n",
    "\n",
    "vacancies.description = vacancies['description'].apply(lambda x: x.lower())\n",
    "vacancies.description = vacancies['description'].replace('<[/\\w]+>', ' ', regex = True)\n",
    "vacancies.description = vacancies['description'].replace('[^ЁёА-яa-zA-Z0-9]', ' ', regex = True)\n",
    "\n",
    "target_vacancies.description = target_vacancies['description'].apply(lambda x: x.lower())\n",
    "target_vacancies.description = target_vacancies['description'].replace('<[/\\w]+>', ' ', regex = True)\n",
    "target_vacancies.description = target_vacancies['description'].replace('[^ЁёА-яa-zA-Z0-9]', ' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' мы занимается разработкой и внедрением программных продуктов с использованием компьютерного зрения и машинного обучения    наш стек  python  c   opencv  pytorch  pandas  tensorflow  openvino  docker    задачи       разработать систему сбора данных и обучения на их основе пайплайна распознавания изображений    сейчас это работает для россии  и нужно будет это масштабировать на весь мир        требования       понимание как хранить данные  и как их обрабатывать    как лучше размечать данные яндекс толока  supervise ly  cvat         как минимум поверхностное понимание нейронных сетей    опыт коммерческой разработки связанной с глубоким обучением    документирование процессов    желательно шарить в nosql базах      условия       работа по тк рф  100  белая зп    гибкий график работы    дружный коллектив единомышленников    возможна удаленка   '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получаем чистое описание\n",
    "target_vacancies['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем TF-IDF для преобрзования описаний в векторы признаков\n",
    "# И при помощи метода min_df оставляем только те, слова, которые встречаются хотя бы в 5-ти документах\n",
    "vectorizer = TfidfVectorizer(min_df=5)\n",
    "X_train_vec = vectorizer.fit_transform(vacancies['description'])\n",
    "X_test_vec = vectorizer.transform(target_vacancies['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем one-hot-encoding для типа занятости\n",
    "enc = DictVectorizer()\n",
    "X_train_categ = enc.fit_transform(vacancies[['employment']].to_dict('records'))\n",
    "X_test_categ = enc.transform(target_vacancies[['employment']].to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединим всё получившееся в одну матрицу 'объекты-признаки'\n",
    "X_for_train = hstack([X_train_vec, X_train_categ])\n",
    "X_for_test = hstack([X_test_vec, X_test_categ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применим гребневую регрессию для обучения\n",
    "ridge = Ridge(alpha=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделим таргеты в отдельный массив\n",
    "y_for_train = vacancies['salary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
       "      random_state=42, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Фитим регрессию нашими признаками: X_train и ответами(таргетами): y_train\n",
    "ridge.fit(X_for_train, y_for_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([172260.65618197, 152617.81816263])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Теперь можно делать предсказание по интересующим нас описаниям\n",
    "ridge.predict(X_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
